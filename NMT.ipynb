{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbup6kqYqeec93f+4BzMcK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiHBaGE9c69p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL2o-4MxdPxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rTulA0ddTS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5fa02e6b-e2ea-4c7a-af32-ae31caa54c45"
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file('spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+'/spa-eng/spa.txt'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFhppr-Beojz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Converting unicode to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilsMVsAgfqFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Sentence preprocessing\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "\n",
        "  w = re.sub(r\"([?.!,多])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  ##replacing everything with space\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,多]+\", \" \", w)\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrLLQt49gguv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31b20c0e-31c3-43f2-8d9e-fa087fe00d18"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"多Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKfUqjukgi67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqwBUy4Kneww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9edef5d5-a10c-4a0b-ab00-d76ee8ad8546"
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmqJcEyunhmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2THWNIX0qwul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0MbQ_xlshuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPKifxwbsPQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "728694bf-040b-4373-955c-539a3994c261"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95171 95171 23793 23793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjcZ7eROsZXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akFJFpIisfC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b460a6f4-feca-4924-8afd-f65d64895be0"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "12 ----> 多\n",
            "103 ----> puedes\n",
            "969 ----> abrir\n",
            "10 ----> la\n",
            "380 ----> ventana\n",
            "11 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "112 ----> could\n",
            "7 ----> you\n",
            "297 ----> open\n",
            "5 ----> the\n",
            "429 ----> window\n",
            "10 ----> ?\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0zkFj67s5It",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Creating a tf dataset\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = int(len(input_tensor_train)/BATCH_SIZE)\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BATCH_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSpYOAy0vVNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a64d76ea-8e04-434b-a02a-1f276927e996"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 53]), TensorShape([64, 51]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvyRGHbcvW8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Encoder decoder with Bandhanau attention\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  recurrent_initializer = 'glorot_uniform')\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units,BATCH_SIZE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq781mKk3Isx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65a5e3ea-16be-40ff-ccff-4e8c2efc3ebd"
      },
      "source": [
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 53, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ4cT_xX4_Bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4o2YKxs80jL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cd3f4f6c-a740-4ec3-996b-ed67b9162127"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 53, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi3e6Bu985WL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA5rVuQJ_hnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "138e71d9-b3fb-4f22-f296-508fc7618443"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 12934)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UAVxPhE_lzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM1llOVN_tUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEDOcgPg_vL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ILeqxDKAJcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be0cff4f-1dc1-4b76-fcbc-b3e4671b7d5c"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.6156\n",
            "Epoch 1 Batch 100 Loss 0.8454\n",
            "Epoch 1 Batch 200 Loss 0.7359\n",
            "Epoch 1 Batch 300 Loss 0.6967\n",
            "Epoch 1 Batch 400 Loss 0.6755\n",
            "Epoch 1 Batch 500 Loss 0.6656\n",
            "Epoch 1 Batch 600 Loss 0.6398\n",
            "Epoch 1 Batch 700 Loss 0.6681\n",
            "Epoch 1 Batch 800 Loss 0.6227\n",
            "Epoch 1 Batch 900 Loss 0.6033\n",
            "Epoch 1 Batch 1000 Loss 0.5718\n",
            "Epoch 1 Batch 1100 Loss 0.6771\n",
            "Epoch 1 Batch 1200 Loss 0.5751\n",
            "Epoch 1 Batch 1300 Loss 0.5907\n",
            "Epoch 1 Batch 1400 Loss 0.5191\n",
            "Epoch 1 Loss 0.6661\n",
            "Time taken for 1 epoch 2065.6838886737823 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.4628\n",
            "Epoch 2 Batch 100 Loss 0.4560\n",
            "Epoch 2 Batch 200 Loss 0.5361\n",
            "Epoch 2 Batch 300 Loss 0.4267\n",
            "Epoch 2 Batch 400 Loss 0.4491\n",
            "Epoch 2 Batch 500 Loss 0.4966\n",
            "Epoch 2 Batch 600 Loss 0.4122\n",
            "Epoch 2 Batch 700 Loss 0.4204\n",
            "Epoch 2 Batch 800 Loss 0.3982\n",
            "Epoch 2 Batch 900 Loss 0.3629\n",
            "Epoch 2 Batch 1000 Loss 0.3993\n",
            "Epoch 2 Batch 1100 Loss 0.3427\n",
            "Epoch 2 Batch 1200 Loss 0.3373\n",
            "Epoch 2 Batch 1300 Loss 0.3572\n",
            "Epoch 2 Batch 1400 Loss 0.3315\n",
            "Epoch 2 Loss 0.4108\n",
            "Time taken for 1 epoch 2010.7144329547882 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.2956\n",
            "Epoch 3 Batch 100 Loss 0.3190\n",
            "Epoch 3 Batch 200 Loss 0.2957\n",
            "Epoch 3 Batch 300 Loss 0.2687\n",
            "Epoch 3 Batch 400 Loss 0.2810\n",
            "Epoch 3 Batch 500 Loss 0.2362\n",
            "Epoch 3 Batch 600 Loss 0.2306\n",
            "Epoch 3 Batch 700 Loss 0.2563\n",
            "Epoch 3 Batch 800 Loss 0.2372\n",
            "Epoch 3 Batch 900 Loss 0.2498\n",
            "Epoch 3 Batch 1000 Loss 0.2779\n",
            "Epoch 3 Batch 1100 Loss 0.2469\n",
            "Epoch 3 Batch 1200 Loss 0.2048\n",
            "Epoch 3 Batch 1300 Loss 0.2160\n",
            "Epoch 3 Batch 1400 Loss 0.1913\n",
            "Epoch 3 Loss 0.2625\n",
            "Time taken for 1 epoch 2005.6970672607422 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.2053\n",
            "Epoch 4 Batch 100 Loss 0.2108\n",
            "Epoch 4 Batch 200 Loss 0.2000\n",
            "Epoch 4 Batch 300 Loss 0.2018\n",
            "Epoch 4 Batch 400 Loss 0.1672\n",
            "Epoch 4 Batch 500 Loss 0.1819\n",
            "Epoch 4 Batch 600 Loss 0.1628\n",
            "Epoch 4 Batch 700 Loss 0.2171\n",
            "Epoch 4 Batch 800 Loss 0.1651\n",
            "Epoch 4 Batch 900 Loss 0.2324\n",
            "Epoch 4 Batch 1000 Loss 0.1966\n",
            "Epoch 4 Batch 1100 Loss 0.2040\n",
            "Epoch 4 Batch 1200 Loss 0.1834\n",
            "Epoch 4 Batch 1300 Loss 0.1566\n",
            "Epoch 4 Batch 1400 Loss 0.1676\n",
            "Epoch 4 Loss 0.1880\n",
            "Time taken for 1 epoch 2004.9316401481628 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1631\n",
            "Epoch 5 Batch 100 Loss 0.1661\n",
            "Epoch 5 Batch 200 Loss 0.1521\n",
            "Epoch 5 Batch 300 Loss 0.1334\n",
            "Epoch 5 Batch 400 Loss 0.1271\n",
            "Epoch 5 Batch 500 Loss 0.1466\n",
            "Epoch 5 Batch 600 Loss 0.1363\n",
            "Epoch 5 Batch 700 Loss 0.1543\n",
            "Epoch 5 Batch 800 Loss 0.0975\n",
            "Epoch 5 Batch 900 Loss 0.1336\n",
            "Epoch 5 Batch 1000 Loss 0.1273\n",
            "Epoch 5 Batch 1100 Loss 0.1314\n",
            "Epoch 5 Batch 1200 Loss 0.1237\n",
            "Epoch 5 Batch 1300 Loss 0.1163\n",
            "Epoch 5 Batch 1400 Loss 0.1302\n",
            "Epoch 5 Loss 0.1412\n",
            "Time taken for 1 epoch 2008.3993737697601 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tuvl9J_ALnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTcNYNFrdJxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z92jZF8KdL-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1NsVHZTdOHX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e40c30d4-7d0f-4fa4-aa2d-76899741be56"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f582c7eeb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucjf4iirdPka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "09ce167f-3e8d-405a-c8c4-4f1198ef8517"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHh34lYZdRYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "bd26f7f8-a866-4d1c-8102-146adf98316b"
      },
      "source": [
        "# wrong translation\n",
        "translate(u'trata de averiguarlo.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> trata de averiguarlo . <end>\n",
            "Predicted translation: try to find out of it . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BwoX8CKdViw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}